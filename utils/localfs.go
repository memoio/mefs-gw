package utils

import (
	"encoding/hex"
	"encoding/json"
	"errors"
	"fmt"
	"io"
	"io/ioutil"
	"os"
	"path"
	"strings"
	"sync"
	"time"

	bsrv "github.com/ipfs/go-blockservice"
	ds "github.com/ipfs/go-datastore"
	dssync "github.com/ipfs/go-datastore/sync"
	blockstore "github.com/ipfs/go-ipfs-blockstore"
	chunker "github.com/ipfs/go-ipfs-chunker"
	offline "github.com/ipfs/go-ipfs-exchange-offline"
	ipld "github.com/ipfs/go-ipld-format"
	dag "github.com/ipfs/go-merkledag"
	"github.com/ipfs/go-unixfs/importer"
	"github.com/spf13/viper"
	"golang.org/x/crypto/blake2b"

	minio "github.com/memoio/minio/cmd"
	"github.com/minio/minio-go/v7/pkg/s3utils"
	"github.com/syndtr/goleveldb/leveldb"
	"github.com/syndtr/goleveldb/leveldb/util"
)

// StorageErr represents error generated by xlStorage call.
type StorageErr string

func (h StorageErr) Error() string {
	return string(h)
}

// errIsNotRegular - not of regular file type.
var errIsNotRegular = StorageErr("not of regular file type")

// Mock returns a new thread-safe, mock DAGService.
func MockDagService() ipld.DAGService {
	return dag.NewDAGService(Bserv())
}

// Bserv returns a new, thread-safe, mock BlockService.
func Bserv() bsrv.BlockService {
	bstore := blockstore.NewBlockstore(dssync.MutexWrap(ds.NewNullDatastore()))
	return bsrv.New(bstore, offline.Exchange(bstore))
}

type BucketInfo struct {
	Name    string `json:"name"`
	Created int64  `json:"created"`
}

type ObjectInfo struct {
	// Name of the bucket.
	Bucket string `json:"bucketname"`

	// Name of the object.
	Name string `json:"name"`

	// Date and time when the object was last modified.
	ModTime int64 `json:"modtime"`

	// Total object size.
	Size int64 `json:"size"`

	// Hex encoded unique entity tag of the object.
	ETag string `json:"etag"`
}

type Bucket struct {
	sync.Mutex
	dir     string
	tempMap map[string]bool
}

// 用于本地存储
type LocalFS struct {
	sync.Mutex                    // 互斥锁
	rootDir    string             // 文件存储的根目录
	tempMap    map[string]*Bucket // 在内存中存储bucket的信息
	meta       *leveldb.DB        // 存储元数据
}

func UserLocalFS(rootpath, BucketName string) (*LocalFS, error) {
	localDir := viper.GetString("common.local_dir")
	if localDir == "" {
		localDir = path.Join(rootpath, "local")
	}
	fmt.Println("Use local fs: ", localDir)
	localfs, err := OpenLocalFS(localDir)
	if err != nil {
		return nil, err
	}

	err = localfs.CheckBucketExist(BucketName)
	if err != nil {
		err = localfs.MakeBucket(BucketName)
		if err != nil {
			return nil, err
		}

	}
	return localfs, nil
}

func OpenLocalFS(rootDir string) (*LocalFS, error) {
	stat, err := os.Stat(rootDir)
	if err == nil && !stat.IsDir() {
		return nil, errors.New("not dir")
	}

	if os.IsNotExist(err) {
		err = os.Mkdir(rootDir, 0777)
		if err != nil {
			return nil, err
		}
	}

	if err != nil {
		return nil, err
	}

	files, err := ioutil.ReadDir(rootDir)
	if err != nil {
		return nil, err
	}

	metaDir := path.Join(rootDir, "meta")
	db, err := leveldb.OpenFile(metaDir, nil)
	if err != nil {
		return nil, err
	}

	sfs := &LocalFS{
		rootDir: rootDir,
		meta:    db,
		tempMap: make(map[string]*Bucket),
	}

	for _, v := range files {
		name := v.Name()
		if v.IsDir() && strings.HasPrefix(name, "bucket.") {
			bname := strings.TrimPrefix(name, "bucket.")
			sfs.tempMap[bname] = &Bucket{
				dir:     path.Join(sfs.rootDir, name),
				tempMap: make(map[string]bool),
			}
		}
	}

	return sfs, nil
}

func (fs *LocalFS) GetBucketPath(bucketName string) string {
	return path.Join(fs.rootDir, "bucket."+bucketName)
}

func GetBucketKey(bucketName string) string {
	return "/" + bucketName
}

func GetObjectKey(bucketName, objectName string) string {
	return "/" + bucketName + "/" + objectName
}

func GetObjectName(key, bucketName string) string {
	return strings.TrimPrefix(key, "/"+bucketName+"/")
}

func (fs *LocalFS) MakeBucket(bucketName string) error {
	fs.Lock()
	defer fs.Unlock()

	bucket, ok := fs.tempMap[bucketName]
	if ok && bucket != nil {
		return minio.BucketExists{Bucket: bucketName}
	}

	err := s3utils.CheckValidBucketNameStrict(bucketName)
	if err != nil {
		return minio.ErrorRespToObjectError(err, bucketName)
	}

	dirPath := fs.GetBucketPath(bucketName)
	if err = os.Mkdir((dirPath), 0777); err != nil {
		return minio.ErrorRespToObjectError(err, bucketName)
	}

	bucket = &Bucket{
		dir:     dirPath,
		tempMap: make(map[string]bool),
	}

	fs.tempMap[bucketName] = bucket
	bucketInfo := BucketInfo{
		Name:    bucketName,
		Created: time.Now().Unix(),
	}

	infoBytes, err := json.Marshal(bucketInfo)
	if err != nil {
		return minio.ErrorRespToObjectError(err, bucketName)
	}

	err = fs.meta.Put([]byte(GetBucketKey(bucketName)), infoBytes, nil)
	if err != nil {
		return minio.ErrorRespToObjectError(err, bucketName)
	}

	return nil
}

func (fs *LocalFS) GetBucketInfo(bucketName string) (bi minio.BucketInfo, err error) {
	err = s3utils.CheckValidBucketNameStrict(bucketName)
	if err != nil {
		return bi, minio.ErrorRespToObjectError(err, bucketName)
	}

	val, err := fs.meta.Get([]byte(GetBucketKey(bucketName)), nil)
	if err != nil {
		return bi, minio.ErrorRespToObjectError(err, bucketName)
	}
	info := &BucketInfo{}
	err = json.Unmarshal(val, info)
	if err != nil {
		return bi, minio.ErrorRespToObjectError(err, bucketName)
	}

	bi.Name = bucketName
	bi.Created = time.Unix(info.Created, 0)

	return bi, nil
}

func (fs *LocalFS) CheckBucketExist(bucketName string) error {
	err := s3utils.CheckValidBucketNameStrict(bucketName)
	if err != nil {
		return minio.ErrorRespToObjectError(err, bucketName)
	}

	dirPath := fs.GetBucketPath(bucketName)
	_, err = os.Stat(dirPath)
	if err != nil {
		return minio.ErrorRespToObjectError(err, bucketName)
	}
	return nil
}

func (fs *LocalFS) GetObjectDirPath(bucketName, objectName string) (string, string) {
	bucketPath := fs.GetBucketPath(bucketName)
	nameHash := blake2b.Sum256([]byte(objectName))
	nameHashStr := hex.EncodeToString(nameHash[:])

	return path.Join(bucketPath, nameHashStr[len(nameHashStr)-3:]), nameHashStr
}

func (fs *LocalFS) PutObject(bucketName, objectName string, r io.Reader) (io.Reader, io.Closer, error) {
	// 检查是否存在对应的bucket
	bucket, ok := fs.tempMap[bucketName]
	if !ok || bucket == nil {
		return nil, nil, minio.BucketNotFound{Bucket: bucketName}
	}

	bucket.Lock()
	// 检查是否有同名的object在上传中
	ok = bucket.tempMap[objectName]
	if ok {
		bucket.Unlock()
		return nil, nil, minio.ObjectAlreadyExists{Bucket: bucketName, Object: objectName}
	}

	bucket.tempMap[objectName] = true
	bucket.Unlock()

	dirPath, nameHashStr := fs.GetObjectDirPath(bucketName, objectName)
	_, err := os.Stat(dirPath)
	// 如果不存在，则创建
	if os.IsNotExist(err) {
		err = os.Mkdir(dirPath, 0777)
		if err != nil {
			return nil, nil, minio.InvalidObjectState{Bucket: bucketName, Object: objectName, Err: err}
		}
	}

	objectPath := path.Join(dirPath, nameHashStr)
	_, err = os.Stat(objectPath)
	if !os.IsNotExist(err) {
		return nil, nil, minio.ObjectAlreadyExists{Bucket: bucketName, Object: objectName}
	}

	temp := objectPath + ".tmp"
	f, err := os.Create(temp)
	if err != nil {
		return nil, nil, minio.ErrorRespToObjectError(err, bucketName, objectName)
	}

	wrapReader := io.TeeReader(r, f)

	return wrapReader, f, err
}

func (fs *LocalFS) FinishPut(bucketName, objectName string, size int64, sucess bool) error {
	bucket, ok := fs.tempMap[bucketName]
	if !ok || bucket == nil {
		return minio.BucketNotFound{Bucket: bucketName}
	}

	dirPath, nameHashStr := fs.GetObjectDirPath(bucketName, objectName)
	_, err := os.Stat(dirPath)
	if os.IsNotExist(err) {
		return minio.InvalidObjectState{Bucket: bucketName, Object: objectName}
	}

	objectPath := path.Join(dirPath, nameHashStr)

	temp := objectPath + ".tmp"

	// 如果上传成功
	if sucess {
		// 重命名
		err = os.Rename(temp, objectPath)
		if err != nil {
			// 失败了把临时文件删除
			os.Remove(temp)
			// 删除缓存的信息
			bucket.Lock()
			delete(bucket.tempMap, objectName)
			bucket.Unlock()

			return minio.ErrorRespToObjectError(err, bucketName, objectName)
		}
		// 删除缓存的信息
		bucket.Lock()
		delete(bucket.tempMap, objectName)

		objectInfo := ObjectInfo{
			Bucket:  bucketName,
			Name:    objectName,
			ModTime: time.Now().Unix(),
			Size:    size,
		}

		val, _ := json.Marshal(objectInfo)

		err = fs.meta.Put([]byte(GetObjectKey(bucketName, objectName)), val, nil)
		bucket.Unlock()
	} else {
		// 失败了把临时文件删除
		err = os.Remove(temp)

		// 删除缓存的信息
		bucket.Lock()
		delete(bucket.tempMap, objectName)
		bucket.Unlock()
	}

	return minio.ErrorRespToObjectError(err, bucketName, objectName)
}

func (fs *LocalFS) GetObject(bucketName, objectName string, offset int64) (io.ReadCloser, int64, error) {
	dirPath, nameHashStr := fs.GetObjectDirPath(bucketName, objectName)
	_, err := os.Stat(dirPath)
	if os.IsNotExist(err) {
		return nil, 0, minio.ObjectNotFound{Bucket: bucketName, Object: objectName}
	}

	objectPath := path.Join(dirPath, nameHashStr)
	_, err = os.Stat(objectPath)
	if os.IsNotExist(err) {
		return nil, 0, minio.ObjectNotFound{Bucket: bucketName, Object: objectName}
	}

	fr, err := os.Open(objectPath)
	if err != nil {
		return nil, 0, minio.ErrorRespToObjectError(err, bucketName, objectName)
	}
	// Stat to get the size of the file at path.
	st, err := fr.Stat()
	if err != nil {
		fr.Close()
		return nil, 0, minio.ErrorRespToObjectError(err, bucketName, objectName)
	}

	// Verify if its not a regular file, since subsequent Seek is undefined.
	if !st.Mode().IsRegular() {
		fr.Close()
		return nil, 0, errIsNotRegular
	}

	// Seek to the requested offset.
	if offset > 0 {
		_, err = fr.Seek(offset, io.SeekStart)
		if err != nil {
			fr.Close()
			return nil, 0, err
		}
	}

	return fr, st.Size(), nil
}

func (fs *LocalFS) GetObjectInfo(bucketName, objectName string) (minio.ObjectInfo, error) {
	objectInfo := minio.ObjectInfo{
		Bucket: bucketName,
		Name:   objectName,
	}
	val, err := fs.meta.Get([]byte(GetObjectKey(bucketName, objectName)), nil)

	if err != nil {
		obInfo := &ObjectInfo{}
		err = json.Unmarshal(val, obInfo)
		if err != nil {
			objectInfo.ModTime = time.Unix(obInfo.ModTime, 0)
			objectInfo.Size = obInfo.Size
		}
	}

	return objectInfo, nil
}

func (fs *LocalFS) ListObjects(bucketName string) (loi minio.ListObjectsInfo, err error) {
	err = s3utils.CheckValidBucketNameStrict(bucketName)
	if err != nil {
		return loi, minio.ErrorRespToObjectError(err, bucketName)
	}

	start := []byte(GetBucketKey(bucketName))
	limit := make([]byte, len(start))
	copy(limit, start)
	limit[len(limit)-1] += 1

	iter := fs.meta.NewIterator(&util.Range{Start: start, Limit: limit}, nil)
	for iter.Next() {
		key := iter.Key()
		val := iter.Value()

		objectName := GetObjectName(string(key), bucketName)
		objectInfo := minio.ObjectInfo{
			Bucket: bucketName,
			Name:   objectName,
		}
		obInfo := &ObjectInfo{}
		err = json.Unmarshal(val, obInfo)
		if err != nil {
			objectInfo.ModTime = time.Unix(obInfo.ModTime, 0)
			objectInfo.Size = obInfo.Size
		}

		loi.Objects = append(loi.Objects, objectInfo)
	}

	return loi, nil
}

func (fs *LocalFS) ListObjectsV2(bucketName string) (loi minio.ListObjectsV2Info, err error) {
	err = s3utils.CheckValidBucketNameStrict(bucketName)
	if err != nil {
		return loi, minio.ErrorRespToObjectError(err, bucketName)
	}

	start := []byte(GetBucketKey(bucketName))
	limit := make([]byte, len(start))
	copy(limit, start)
	limit[len(limit)-1] += 1

	iter := fs.meta.NewIterator(&util.Range{Start: start, Limit: limit}, nil)
	for iter.Next() {
		key := iter.Key()
		val := iter.Value()

		objectName := GetObjectName(string(key), bucketName)
		objectInfo := minio.ObjectInfo{
			Bucket: bucketName,
			Name:   objectName,
		}
		obInfo := &ObjectInfo{}
		err = json.Unmarshal(val, obInfo)
		if err != nil {
			objectInfo.ModTime = time.Unix(obInfo.ModTime, 0)
			objectInfo.Size = obInfo.Size
		}

		loi.Objects = append(loi.Objects, objectInfo)
	}

	return loi, nil
}

func (fs *LocalFS) CidOf(bucketName, objectName string) (string, error) {
	dirPath, nameHashStr := fs.GetObjectDirPath(bucketName, objectName)
	_, err := os.Stat(dirPath)
	if os.IsNotExist(err) {
		return "", minio.ObjectNotFound{Bucket: bucketName, Object: objectName}
	}

	objectPath := path.Join(dirPath, nameHashStr)
	_, err = os.Stat(objectPath)
	if os.IsNotExist(err) {
		return "", minio.ObjectNotFound{Bucket: bucketName, Object: objectName}
	}

	f, err := os.Open(objectPath)
	if err != nil {
		return "", minio.ErrorRespToObjectError(err, bucketName, objectName)
	}

	ds := MockDagService()
	nd, err := importer.BuildDagFromReader(ds, chunker.NewSizeSplitter(f, chunker.DefaultBlockSize))
	if err != nil {
		return "", nil
	}
	return nd.Cid().String(), nil
}

func (fs *LocalFS) DeleteObject(bucketName, objectName string) error {
	p := path.Join(fs.GetBucketPath(bucketName), objectName)
	err := os.Remove(p)
	if err != nil {
		return err
	}

	err = fs.meta.Delete([]byte(GetObjectKey(bucketName, objectName)), nil)
	return err
}
